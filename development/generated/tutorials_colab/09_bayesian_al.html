
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Bayesian Active Learning &#8212; scikit-activeml development documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=249f3023"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'generated/tutorials_colab/09_bayesian_al';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-activeml.github.io/latest/_static/switcher.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'development';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="../../_static/filter_examples.js?v=52a8636b"></script>
    <link rel="canonical" href="https://scikit-activeml.github.io/development/generated/tutorials_colab/09_bayesian_al.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="development" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/scikit-activeml-logo.png" class="logo__image only-light" alt="scikit-activeml development documentation - Home"/>
    <img src="../../_static/scikit-activeml-logo.png" class="logo__image only-dark pst-js-only" alt="scikit-activeml development documentation - Home"/>
  
  
</a></div>
    
      <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../index.html">
    Home
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../strategy_overview.html">
    Strategy Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../sphinx_gallery_examples/index.html">
    Visualizations
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/skactiveml.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/scikit-activeml/scikit-activeml/releases">
    Changelog
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-activeml/scikit-activeml" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-activeml" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fas fa-box fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../index.html">
    Home
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../tutorials.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../strategy_overview.html">
    Strategy Overview
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../sphinx_gallery_examples/index.html">
    Visualizations
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/skactiveml.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing.html">
    Contributing
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/scikit-activeml/scikit-activeml/releases">
    Changelog
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-activeml/scikit-activeml" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/scikit-activeml" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fas fa-box fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Bayesian Active Learning</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Bayesian-Active-Learning">
<h1>Bayesian Active Learning<a class="headerlink" href="#Bayesian-Active-Learning" title="Link to this heading">#</a></h1>
<blockquote>
<div><p><strong>Google Colab Note:</strong> If the notebook fails to run after installing the needed packages, try to restart the runtime (Ctrl + M) under Runtime -&gt; Restart session.</p>
</div></blockquote>
<p><a class="reference external" href="https://colab.research.google.com/github/scikit-activeml/scikit-activeml.github.io/blob/gh-pages/development/generated/tutorials_colab//09_bayesian_al.ipynb"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p><strong>Notebook Dependencies</strong></p>
<p>Uncomment the following cells to install all dependencies for this tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio<span class="w"> </span>transformers<span class="w"> </span>datasets<span class="o">[</span>audio<span class="o">]</span>
</pre></div>
</div>
</div>
<hr style="border-style: solid; border-top: 1px solid; border-right: 0; border-bottom: 0; border-left: 0;"><p>This tutorial illustrates how Bayesian active learning query strategies can be applied within <code class="docutils literal notranslate"><span class="pre">scikit-activeml</span></code> to an audio classification task. In particular, we demonstrate pool-based active learning on the AudioMNIST dataset, where raw audio signals are first transformed into fixed embeddings using a pretrained Wav2Vec 2.0 model. These embeddings serve as input to a lightweight classification head, enabling efficient training and uncertainty estimation.</p>
<p>The main focus of this notebook is on <strong>Bayesian active learning</strong>, where epistemic uncertainty is approximated via Monte Carlo (MC) dropout and exploited by Bayesian query strategies available in <code class="docutils literal notranslate"><span class="pre">scikit-activeml</span></code>, such as uncertainty-based or information-theoretic selection methods. By repeatedly querying the most informative audio samples for annotation, we aim to achieve strong predictive performance with a minimal labeling budget.</p>
<p>From a structural perspective, this tutorial closely follows the general workflow used in other deep active learning examples in <code class="docutils literal notranslate"><span class="pre">scikit-activeml</span></code>:</p>
<ol class="arabic simple">
<li><p>dataset preparation and embedding extraction,</p></li>
<li><p>definition of a neural network <code class="docutils literal notranslate"><span class="pre">pytorch</span></code> module,</p></li>
<li><p>specification of Bayesian query strategies,</p></li>
<li><p>execution of an active learning loop with iterative querying and retraining.</p></li>
</ol>
<p>Compared to image-based tutorials (e.g., those using frozen Vision Transformers), this notebook highlights how the same active learning principles transfer seamlessly to the audio domain. In doing so, it demonstrates that <code class="docutils literal notranslate"><span class="pre">scikit-activeml</span></code> can be combined with modern audio foundation models for speech processing to perform Bayesian active learning on real-world audio data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mlp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">Audio</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">skactiveml.classifier</span><span class="w"> </span><span class="kn">import</span> <span class="n">SkorchClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">skactiveml.pool</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">RandomSampling</span><span class="p">,</span>
    <span class="n">UncertaintySampling</span><span class="p">,</span>
    <span class="n">GreedyBALD</span><span class="p">,</span>
    <span class="n">BatchBALD</span><span class="p">,</span>
    <span class="n">QueryByCommittee</span><span class="p">,</span>
    <span class="n">SubSamplingWrapper</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">skactiveml.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">call_func</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">skorch.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">LRScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">CosineAnnealingLR</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoFeatureExtractor</span><span class="p">,</span> <span class="n">Wav2Vec2Model</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">mlp</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.facecolor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;white&quot;</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">missing_label</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</pre></div>
</div>
</div>
<section id="Embed-AudioMNIST-with-Wac2Vec">
<h2>Embed AudioMNIST with Wac2Vec<a class="headerlink" href="#Embed-AudioMNIST-with-Wac2Vec" title="Link to this heading">#</a></h2>
<p>We turn the raw AudioMNIST waveforms into fixed-size feature vectors using a pretrained Wav2Vec 2.0 model. We first resample all audio clips to the sampling rate expected by Wav2Vec, then use the corresponding feature extractor and model to obtain hidden representations. For each recording, we pool the hidden states into a single embedding vector (e.g., by averaging over time). These embeddings are stored as our feature matrix <code class="docutils literal notranslate"><span class="pre">X</span></code>, while the spoken digit labels form <code class="docutils literal notranslate"><span class="pre">y</span></code>. All subsequent
active learning steps in <code class="docutils literal notranslate"><span class="pre">scikit-activeml</span></code> operate only on these precomputed Wav2Vec embeddings, without re-running the foundation model.</p>
<blockquote>
<div><p><strong>Note:</strong> The execution time strongly depends on whether a GPU or CPU will be used.</p>
</div></blockquote>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Spoken digit dataset: 0â€“9, circa 30k clips of 60 speakers</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;gilkeyio/AudioMNIST&quot;</span><span class="p">)</span>

<span class="c1"># Use provided train / test splits</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>

<span class="c1"># Ensure a fixed sampling rate for all audio (16 kHz for Wav2Vec2)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">))</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">))</span>

<span class="c1"># Load audio foundation model (wav2vec2-base)</span>
<span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">AutoFeatureExtractor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/wav2vec2-base&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Wav2Vec2Model</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/wav2vec2-base&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">embed</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">audio_arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">[</span><span class="s2">&quot;array&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;audio&quot;</span><span class="p">]]</span>
    <span class="n">sampling_rate</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;sampling_rate&quot;</span><span class="p">]</span>

    <span class="n">inputs</span> <span class="o">=</span> <span class="n">feature_extractor</span><span class="p">(</span>
        <span class="n">audio_arrays</span><span class="p">,</span>
        <span class="n">sampling_rate</span><span class="o">=</span><span class="n">sampling_rate</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
        <span class="c1"># Global mean pooling</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;emb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">emb</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">batch</span>


<span class="c1"># Map without multiprocessing</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Digit labels: 0-9</span>
<span class="n">label_col</span> <span class="o">=</span> <span class="s2">&quot;digit&quot;</span>

<span class="c1"># Create numpy arrays</span>
<span class="n">X_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;emb&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_pool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="n">label_col</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s2">&quot;emb&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="n">label_col</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="n">X_pool</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_pool</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "2fe6973368f94afb975c126a0aa268f5"}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "6ebeeeb6daff4f92a6a82c78af5b4688"}</script></div>
</div>
</section>
<section id="PyTorch-Module-with-Monte-Carlo-Dropout">
<h2>PyTorch Module with Monte-Carlo Dropout<a class="headerlink" href="#PyTorch-Module-with-Monte-Carlo-Dropout" title="Link to this heading">#</a></h2>
<p>This following module assumes that the inputs are fixed embeddings produced by a (possibly frozen) foundational model. During training, dropout is applied directly to the input embeddings with a different random mask for each forward pass. During evaluation, if Monte Carlo (MC) dropout is enabled, a fixed set of dropout masks is sampled once and reused across multiple forward calls, so that each MC sample can be interpreted as a persistent ensemble member.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ClassificationModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;MLP classifier with optional MC dropout on input embeddings.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_features : int</span>
<span class="sd">        Dimensionality of the input embeddings.</span>
<span class="sd">    n_classes : int</span>
<span class="sd">        Number of output classes.</span>
<span class="sd">    n_hidden_units : int</span>
<span class="sd">        Number of hidden units in the hidden layer.</span>
<span class="sd">    mc_dropout_p : float, default=0.5</span>
<span class="sd">        Dropout probability applied to the input embeddings. Used during</span>
<span class="sd">        training for regularization and, if MC sampling is enabled, during</span>
<span class="sd">        evaluation by means of fixed dropout masks.</span>
<span class="sd">    n_mc_samples : int, default=0</span>
<span class="sd">        Number of MC dropout samples in evaluation mode. If</span>
<span class="sd">        ``n_mc_samples &lt;= 1`` or ``mc_dropout_p &lt;= 0``, evaluation is</span>
<span class="sd">        deterministic and no MC statistics are returned.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_features</span><span class="p">,</span>
        <span class="n">n_classes</span><span class="p">,</span>
        <span class="n">n_hidden_units</span><span class="p">,</span>
        <span class="n">mc_dropout_p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">n_mc_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_hidden_units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden_units</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mc_dropout_p</span> <span class="o">=</span> <span class="n">mc_dropout_p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mc_samples</span> <span class="o">=</span> <span class="n">n_mc_samples</span>

        <span class="c1"># Fixed dropout masks (n_mc_samples, n_features), used only in eval.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;mc_masks&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_mc_enabled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return True if MC dropout is configured to be active in eval.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_mc_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_mc_samples</span> <span class="o">&gt;</span> <span class="mi">1</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc_dropout_p</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_mc_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">n_features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample fixed dropout masks if MC is enabled and masks are missing.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mc_enabled</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mc_masks</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span>

        <span class="n">expected_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_mc_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc_masks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc_masks</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">expected_shape</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc_dropout_p</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
            <span class="o">*</span><span class="n">expected_shape</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">bernoulli_</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">)</span> <span class="o">/</span> <span class="n">keep_prob</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mc_masks</span> <span class="o">=</span> <span class="n">mask</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_head</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shared MLP head.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor of shape (batch_size, n_features)</span>
<span class="sd">            Input embeddings or masked embeddings.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        logits : torch.Tensor of shape (batch_size, n_classes)</span>
<span class="sd">            Class logits.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_2</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute logits and, in evaluation mode, optional MC statistics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor of shape (n_samples, n_features)</span>
<span class="sd">            Input embeddings.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Training mode (``self.training is True``)</span>
<span class="sd">            logits : torch.Tensor of shape (n_samples, n_classes)</span>
<span class="sd">                Class logits from a single forward pass with standard dropout</span>
<span class="sd">                on the input embeddings.</span>

<span class="sd">        Evaluation mode, MC disabled</span>
<span class="sd">            logits : torch.Tensor of shape (n_samples, n_classes)</span>
<span class="sd">                Deterministic class logits from a single forward pass without</span>
<span class="sd">                dropout on the input embeddings.</span>

<span class="sd">        Evaluation mode, MC enabled</span>
<span class="sd">            logits_mean : torch.Tensor of shape (n_samples, n_classes)</span>
<span class="sd">                Mean logits over MC ensemble members, i.e.</span>
<span class="sd">                ``logits_mc.mean(axis=1)``.</span>
<span class="sd">            logits_mc : torch.Tensor of shape (n_samples, n_mc_samples, n_classes)</span>
<span class="sd">                Logits for each MC ensemble member, obtained by applying the</span>
<span class="sd">                fixed dropout masks to the input embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># Training: standard dropout with varying masks</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc_dropout_p</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">x_dropped</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mc_dropout_p</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x_dropped</span> <span class="o">=</span> <span class="n">x</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_head</span><span class="p">(</span><span class="n">x_dropped</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">logits</span>

        <span class="c1"># Evaluation, MC disabled: deterministic forward without dropout</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mc_enabled</span><span class="p">():</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">logits</span>

        <span class="c1"># Evaluation, MC enabled: use fixed masks as ensemble members</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_mc_masks</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc_masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Safety fallback: behave as if MC were disabled</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">logits</span>

        <span class="c1"># x: (B, F) -&gt; (B, 1, F)</span>
        <span class="n">x_expanded</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># mc_masks: (S, F) -&gt; (1, S, F)</span>
        <span class="n">mc_masks_expanded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc_masks</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Apply fixed masks: (B, S, F)</span>
        <span class="n">x_masked</span> <span class="o">=</span> <span class="n">x_expanded</span> <span class="o">*</span> <span class="n">mc_masks_expanded</span>

        <span class="c1"># Flatten batch and sample dims for shared head: (B * S, F)</span>
        <span class="n">x_masked_flat</span> <span class="o">=</span> <span class="n">x_masked</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
        <span class="n">logits_mc_flat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_head</span><span class="p">(</span><span class="n">x_masked_flat</span><span class="p">)</span>
        <span class="c1"># Reshape back to (B, S, C)</span>
        <span class="n">logits_mc</span> <span class="o">=</span> <span class="n">logits_mc_flat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_mc_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits_mean</span> <span class="o">=</span> <span class="n">logits_mc</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits_mean</span><span class="p">,</span> <span class="n">logits_mc</span>
</pre></div>
</div>
</div>
</section>
<section id="Bayesian-Skorch-Classifier">
<h2>Bayesian Skorch Classifier<a class="headerlink" href="#Bayesian-Skorch-Classifier" title="Link to this heading">#</a></h2>
<p>In this step, we define a <code class="docutils literal notranslate"><span class="pre">BayesianSkorchClassifier</span></code> that extends <code class="docutils literal notranslate"><span class="pre">SkorchClassifier</span></code> with a sample_proba method, which returns the class probabilities predicted by each individual ensemble member (e.g., MC dropout samples). We then initialize the classifier with the ClassificationModule as <code class="docutils literal notranslate"><span class="pre">pytorch</span></code> module, configure MC dropout via <code class="docutils literal notranslate"><span class="pre">n_mc_samples</span></code> and <code class="docutils literal notranslate"><span class="pre">mc_dropout_p</span></code>, and set standard training hyperparameters such as optimizer, learning rate, batch size, and learning rate scheduler.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BayesianSkorchClassifier</span><span class="p">(</span><span class="n">SkorchClassifier</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper class implement a function returning the predicted class probabilities</span>
<span class="sd">    predicted by the individual ensemble members.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the predicted class probabilities predicted by</span>
<span class="sd">         the individual ensemble members.</span>

<span class="sd">         Parameters</span>
<span class="sd">         ----------</span>
<span class="sd">         X : numpy.ndarray of shape (n_samples, n_features)</span>
<span class="sd">            Test samples</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        P_mc : numpy.ndarray of shape (n_members, n_samples, n_classes)</span>
<span class="sd">            Probabilities predicted by the individual ensemble members.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Swap axes to have desired shape.</span>
        <span class="n">P_mc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">extra_outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;probas_mc&quot;</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">P_mc</span>


<span class="c1"># Initialize classifier including training hyperparameters.</span>
<span class="n">clf_init</span> <span class="o">=</span> <span class="n">BayesianSkorchClassifier</span><span class="p">(</span>
    <span class="n">module</span><span class="o">=</span><span class="n">ClassificationModule</span><span class="p">,</span>
    <span class="n">criterion</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">,</span>
    <span class="n">forward_outputs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;proba&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)),</span> <span class="s2">&quot;probas_mc&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))},</span>
    <span class="n">neural_net_param_dict</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># Module-related parameters.</span>
        <span class="s2">&quot;module__n_features&quot;</span><span class="p">:</span> <span class="n">n_features</span><span class="p">,</span>
        <span class="s2">&quot;module__n_hidden_units&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
        <span class="s2">&quot;module__n_classes&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span>
        <span class="s2">&quot;module__n_mc_samples&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s2">&quot;module__mc_dropout_p&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="c1"># Optimizer-related parameters.</span>
        <span class="s2">&quot;max_epochs&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
        <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">RAdam</span><span class="p">,</span>
        <span class="s2">&quot;callbacks&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">(</span><span class="s2">&quot;lr_scheduler&quot;</span><span class="p">,</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="n">CosineAnnealingLR</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">50</span><span class="p">))</span>
        <span class="p">],</span>
        <span class="c1"># General parameters.</span>
        <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span>
        <span class="s2">&quot;train_split&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;iterator_train__shuffle&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
    <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
<section id="Active-Classification">
<h2>Active Classification<a class="headerlink" href="#Active-Classification" title="Link to this heading">#</a></h2>
<p>For our classifier, we evaluate five different query strategies regarding their sample selection. For this purpose, we start with <code class="docutils literal notranslate"><span class="pre">n_init_labels=64</span></code> initial labels selected via random sampling and make <code class="docutils literal notranslate"><span class="pre">n_cycles=10</span></code> iterations of an active learning cycle with <code class="docutils literal notranslate"><span class="pre">batch_size=32</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define setup.</span>
<span class="n">n_cycles</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">n_sub_set</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">n_init_labels</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">qs_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;RandomSampling&quot;</span><span class="p">:</span> <span class="n">RandomSampling</span><span class="p">(</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span>
    <span class="p">),</span>
    <span class="s2">&quot;UncertaintySampling&quot;</span><span class="p">:</span> <span class="n">UncertaintySampling</span><span class="p">(</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;margin_sampling&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="s2">&quot;QBC&quot;</span><span class="p">:</span> <span class="n">QueryByCommittee</span><span class="p">(</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;vote_entropy&quot;</span><span class="p">,</span>
        <span class="n">sample_predictions_method_name</span><span class="o">=</span><span class="s2">&quot;sample_proba&quot;</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="s2">&quot;GreedyBALD&quot;</span><span class="p">:</span> <span class="n">GreedyBALD</span><span class="p">(</span>
        <span class="n">sample_predictions_method_name</span><span class="o">=</span><span class="s2">&quot;sample_proba&quot;</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="s2">&quot;BatchBALD&quot;</span><span class="p">:</span> <span class="n">BatchBALD</span><span class="p">(</span>
        <span class="n">sample_predictions_method_name</span><span class="o">=</span><span class="s2">&quot;sample_proba&quot;</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">}</span>
<span class="n">acc_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_cycles</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">qs_dict</span><span class="p">}</span>


<span class="c1"># Perform active learning with each query strategy.</span>
<span class="k">for</span> <span class="n">qs_name</span><span class="p">,</span> <span class="n">qs</span> <span class="ow">in</span> <span class="n">qs_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Execute active learning using </span><span class="si">{</span><span class="n">qs_name</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="c1"># Set seed and copy classifier for consistent initialization.</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">clf_init</span><span class="p">)</span>

    <span class="c1"># Wrapper to subsample unlabeled samples.</span>
    <span class="n">qs</span> <span class="o">=</span> <span class="n">SubSamplingWrapper</span><span class="p">(</span>
        <span class="n">query_strategy</span><span class="o">=</span><span class="n">qs</span><span class="p">,</span>
        <span class="n">max_candidates</span><span class="o">=</span><span class="n">n_sub_set</span><span class="p">,</span>
        <span class="n">exclude_non_subsample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">qs_init</span> <span class="o">=</span> <span class="n">RandomSampling</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">missing_label</span><span class="o">=</span><span class="n">missing_label</span><span class="p">)</span>

    <span class="c1"># Create array with 64 initial labels.</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">y_pool</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">missing_label</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">init_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="n">n_init_labels</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pool</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span>

    <span class="c1"># Execute active learning cycle.</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_cycles</span><span class="p">)):</span>
        <span class="c1"># Fit and evaluate clf.</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_pool</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="n">acc_dict</span><span class="p">[</span><span class="n">qs_name</span><span class="p">][</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span>

        <span class="c1"># Select and update training data.</span>
        <span class="n">query_idx</span> <span class="o">=</span> <span class="n">call_func</span><span class="p">(</span>
            <span class="n">qs</span><span class="o">.</span><span class="n">query</span><span class="p">,</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X_pool</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
            <span class="n">clf</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span>
            <span class="n">fit_clf</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">ensemble</span><span class="o">=</span><span class="n">clf</span><span class="p">,</span>
            <span class="n">fit_ensemble</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">y</span><span class="p">[</span><span class="n">query_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pool</span><span class="p">[</span><span class="n">query_idx</span><span class="p">]</span>

    <span class="c1"># Fit and evaluate clf.</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_pool</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">acc_dict</span><span class="p">[</span><span class="n">qs_name</span><span class="p">][</span><span class="n">n_cycles</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Execute active learning using RandomSampling.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06&lt;00:00,  1.52it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Execute active learning using UncertaintySampling.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07&lt;00:00,  1.38it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Execute active learning using QBC.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07&lt;00:00,  1.38it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Execute active learning using GreedyBALD.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07&lt;00:00,  1.36it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Execute active learning using BatchBALD.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12&lt;00:00,  1.24s/it]
</pre></div></div>
</div>
</section>
<section id="Visualize-Results">
<h2>Visualize Results<a class="headerlink" href="#Visualize-Results" title="Link to this heading">#</a></h2>
<p>In the following, we plot the obtained learning curves including the area under learning curve (AULC) scores per query strategy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cycles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_cycles</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">qs_name</span><span class="p">,</span> <span class="n">acc</span> <span class="ow">in</span> <span class="n">acc_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">cycles</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span>
        <span class="n">acc</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">qs_name</span><span class="si">}</span><span class="s2">: AULC=</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">cycles</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;# labeled samples&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;test accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span><span class="c1">#%%</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/generated_tutorials_colab_09_bayesian_al_16_0.png" src="../../_images/generated_tutorials_colab_09_bayesian_al_16_0.png" />
</div>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Embed-AudioMNIST-with-Wac2Vec">Embed AudioMNIST with Wac2Vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#PyTorch-Module-with-Monte-Carlo-Dropout">PyTorch Module with Monte-Carlo Dropout</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Bayesian-Skorch-Classifier">Bayesian Skorch Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Active-Classification">Active Classification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Visualize-Results">Visualize Results</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/generated/tutorials_colab/09_bayesian_al.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      Â© Copyright 2025.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>